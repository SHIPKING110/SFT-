# scripts/chat_with_model.py
import os
import torch
import json
from datetime import datetime
from typing import List, Dict, Any
from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer
)

class ChatBot:
    def __init__(self, model_path: str):
        """åˆå§‹åŒ–èŠå¤©æœºå™¨äºº"""
        self.model_path = model_path
        self.conversation_history = []
        
        print(f"ğŸ¤– åŠ è½½æ¨¡å‹: {model_path}")
        self.load_model()
        print("âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼Œå¯ä»¥å¼€å§‹å¯¹è¯äº†ï¼")
        print("ğŸ’¡ è¾“å…¥ 'é€€å‡º' æˆ– 'quit' ç»“æŸå¯¹è¯")
        print("ğŸ’¡ è¾“å…¥ 'æ¸…é™¤' æˆ– 'clear' æ¸…é™¤å¯¹è¯å†å²")
        print("ğŸ’¡ è¾“å…¥ 'ä¿å­˜' æˆ– 'save' ä¿å­˜å¯¹è¯è®°å½•")
        print("-" * 60)
    
    def load_model(self):
        """åŠ è½½æ¨¡å‹å’Œtokenizer"""
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(
                self.model_path, 
                trust_remote_code=True
            )
            
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
                
            self.model = AutoModelForCausalLM.from_pretrained(
                self.model_path,
                torch_dtype=torch.float16,
                device_map="auto",
                trust_remote_code=True
            )
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def format_conversation(self, messages: List[Dict]) -> str:
        """æ ¼å¼åŒ–å¯¹è¯å†å²"""
        formatted_text = ""
        for msg in messages:
            if msg["role"] == "user":
                formatted_text += f"ç”¨æˆ·ï¼š{msg['content']}\n"
            elif msg["role"] == "assistant":
                formatted_text += f"åŠ©æ‰‹ï¼š{msg['content']}\n"
        return formatted_text.strip()
    
    def generate_response(self, user_input: str, max_length: int = 1024) -> str:
        """ç”Ÿæˆå›å¤"""
        try:
            # æ·»åŠ ç”¨æˆ·è¾“å…¥åˆ°å¯¹è¯å†å²
            self.conversation_history.append({"role": "user", "content": user_input})
            
            # æ ¼å¼åŒ–å¯¹è¯
            prompt = self.format_conversation(self.conversation_history) + "\nåŠ©æ‰‹ï¼š"
            
            # ç¼–ç è¾“å…¥
            inputs = self.tokenizer(prompt, return_tensors="pt", truncation=True, max_length=2048)
            inputs = {k: v.to(self.model.device) for k, v in inputs.items()}
            
            # ç”Ÿæˆå›å¤
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_new_tokens=max_length,
                    do_sample=True,
                    temperature=0.7,
                    top_p=0.9,
                    pad_token_id=self.tokenizer.pad_token_id,
                    eos_token_id=self.tokenizer.eos_token_id,
                    repetition_penalty=1.1
                )
            
            # è§£ç å›å¤
            response = self.tokenizer.decode(outputs[0][len(inputs['input_ids'][0]):], skip_special_tokens=True)
            response = response.strip()
            
            # æ·»åŠ åˆ°å¯¹è¯å†å²
            self.conversation_history.append({"role": "assistant", "content": response})
            
            return response
            
        except Exception as e:
            print(f"ç”Ÿæˆå›å¤æ—¶å‡ºé”™: {e}")
            return "æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼Œè¯·é‡æ–°å°è¯•ã€‚"
    
    def extract_reasoning_and_answer(self, response: str) -> tuple:
        """ä»å›å¤ä¸­æå–æ¨ç†è¿‡ç¨‹å’Œæœ€ç»ˆç­”æ¡ˆ"""
        reasoning = ""
        answer = ""
        
        if "<reasoning>" in response and "</reasoning>" in response:
            # æå–æ¨ç†éƒ¨åˆ†
            start_idx = response.find("<reasoning>") + len("<reasoning>")
            end_idx = response.find("</reasoning>")
            reasoning = response[start_idx:end_idx].strip()
            
            # æå–ç­”æ¡ˆéƒ¨åˆ†
            answer_start = response.find("ç­”ï¼š")
            if answer_start != -1:
                answer = response[answer_start + len("ç­”ï¼š"):].strip()
        else:
            # å¦‚æœæ²¡æœ‰ç‰¹å®šæ ¼å¼ï¼Œå°è¯•åˆ†å‰²
            if "ç­”ï¼š" in response:
                answer_start = response.find("ç­”ï¼š")
                reasoning = response[:answer_start].strip()
                answer = response[answer_start + len("ç­”ï¼š"):].strip()
            else:
                answer = response
        
        return reasoning, answer
    
    def save_conversation(self, filename: str = None):
        """ä¿å­˜å¯¹è¯è®°å½•"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"conversation_{timestamp}.json"
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs("./conversations", exist_ok=True)
        filepath = os.path.join("./conversations", filename)
        
        conversation_data = {
            "model_path": self.model_path,
            "timestamp": datetime.now().isoformat(),
            "conversation": self.conversation_history
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(conversation_data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ å¯¹è¯å·²ä¿å­˜åˆ°: {filepath}")
        return filepath
    
    def load_conversation(self, filepath: str):
        """åŠ è½½å¯¹è¯è®°å½•"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                conversation_data = json.load(f)
            
            self.conversation_history = conversation_data["conversation"]
            print(f"ğŸ“‚ å·²åŠ è½½å¯¹è¯è®°å½•ï¼Œå…± {len(self.conversation_history)} æ¡æ¶ˆæ¯")
            
            # æ˜¾ç¤ºæœ€è¿‘çš„å‡ æ¡æ¶ˆæ¯
            print("\næœ€è¿‘çš„å¯¹è¯:")
            for msg in self.conversation_history[-4:]:  # æ˜¾ç¤ºæœ€å4æ¡
                role = "ç”¨æˆ·" if msg["role"] == "user" else "åŠ©æ‰‹"
                print(f"  {role}: {msg['content'][:100]}...")
                
        except Exception as e:
            print(f"âŒ åŠ è½½å¯¹è¯å¤±è´¥: {e}")
    
    def clear_conversation(self):
        """æ¸…é™¤å¯¹è¯å†å²"""
        self.conversation_history = []
        print("ğŸ—‘ï¸  å¯¹è¯å†å²å·²æ¸…é™¤")
    
    def print_conversation_stats(self):
        """æ‰“å°å¯¹è¯ç»Ÿè®¡"""
        user_msgs = len([msg for msg in self.conversation_history if msg["role"] == "user"])
        assistant_msgs = len([msg for msg in self.conversation_history if msg["role"] == "assistant"])
        
        print(f"\nğŸ“Š å¯¹è¯ç»Ÿè®¡:")
        print(f"   ç”¨æˆ·æ¶ˆæ¯: {user_msgs} æ¡")
        print(f"   åŠ©æ‰‹å›å¤: {assistant_msgs} æ¡")
        print(f"   æ€»æ¶ˆæ¯æ•°: {len(self.conversation_history)} æ¡")
    
    def start_chat(self):
        """å¼€å§‹èŠå¤©ä¼šè¯"""
        print("ğŸ¯ å¼€å§‹å¯¹è¯...")
        
        while True:
            try:
                # è·å–ç”¨æˆ·è¾“å…¥
                user_input = input("\nğŸ‘¤ ä½ : ").strip()
                
                # å¤„ç†ç‰¹æ®Šå‘½ä»¤
                if user_input.lower() in ['é€€å‡º', 'quit', 'exit']:
                    print("ğŸ‘‹ å†è§ï¼")
                    break
                
                elif user_input.lower() in ['æ¸…é™¤', 'clear']:
                    self.clear_conversation()
                    continue
                
                elif user_input.lower() in ['ä¿å­˜', 'save']:
                    self.save_conversation()
                    continue
                
                elif user_input.lower() in ['ç»Ÿè®¡', 'stats']:
                    self.print_conversation_stats()
                    continue
                
                elif user_input.lower() in ['å¸®åŠ©', 'help']:
                    self.print_help()
                    continue
                
                elif user_input.lower() in ['åŠ è½½', 'load']:
                    filename = input("è¯·è¾“å…¥å¯¹è¯æ–‡ä»¶è·¯å¾„: ").strip()
                    self.load_conversation(filename)
                    continue
                
                # ç©ºè¾“å…¥
                if not user_input:
                    continue
                
                # ç”Ÿæˆå›å¤
                print("ğŸ¤– åŠ©æ‰‹æ€è€ƒä¸­...", end="", flush=True)
                response = self.generate_response(user_input)
                print("\r" + " " * 50 + "\r", end="")  # æ¸…é™¤"æ€è€ƒä¸­"æç¤º
                
                # è§£æå›å¤
                reasoning, answer = self.extract_reasoning_and_answer(response)
                
                # æ‰“å°å›å¤
                print("ğŸ¤– åŠ©æ‰‹:")
                if reasoning:
                    print(f"  æ¨ç†è¿‡ç¨‹: {reasoning}")
                if answer:
                    print(f"  ç­”æ¡ˆ: {answer}")
                if not reasoning and not answer:
                    print(f"  {response}")
                
                # æ˜¾ç¤ºå¯¹è¯è½®æ•°
                current_turn = len([msg for msg in self.conversation_history if msg["role"] == "user"])
                print(f"  (ç¬¬ {current_turn} è½®å¯¹è¯)")
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œå†è§ï¼")
                break
            except Exception as e:
                print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
                continue
    
    def print_help(self):
        """æ‰“å°å¸®åŠ©ä¿¡æ¯"""
        print("\nğŸ“– å¯ç”¨å‘½ä»¤:")
        print("  'é€€å‡º'/'quit' - ç»“æŸå¯¹è¯")
        print("  'æ¸…é™¤'/'clear' - æ¸…é™¤å¯¹è¯å†å²")
        print("  'ä¿å­˜'/'save' - ä¿å­˜å¯¹è¯è®°å½•")
        print("  'ç»Ÿè®¡'/'stats' - æ˜¾ç¤ºå¯¹è¯ç»Ÿè®¡")
        print("  'åŠ è½½'/'load' - åŠ è½½å¯¹è¯è®°å½•")
        print("  'å¸®åŠ©'/'help' - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯")
        print("-" * 40)

def select_model():
    """é€‰æ‹©æ¨¡å‹"""
    models_dir = "./models"
    available_models = []
    
    if os.path.exists(models_dir):
        for item in os.listdir(models_dir):
            model_path = os.path.join(models_dir, item)
            if os.path.isdir(model_path):
                # æ£€æŸ¥æ˜¯å¦æœ‰æœ€ä½³æ¨¡å‹
                best_model_path = os.path.join(model_path, "best_model")
                final_model_path = os.path.join(model_path, "final_model")
                
                if os.path.exists(best_model_path):
                    available_models.append((f"{item}/best_model", best_model_path))
                if os.path.exists(final_model_path):
                    available_models.append((f"{item}/final_model", final_model_path))
                # å¦‚æœæ²¡æœ‰å­ç›®å½•ï¼Œç›´æ¥ä½¿ç”¨æ¨¡å‹ç›®å½•
                elif any(f.endswith('.bin') or f.endswith('.safetensors') for f in os.listdir(model_path)):
                    available_models.append((item, model_path))
    
    if not available_models:
        print("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹ï¼Œè¯·æŒ‡å®šæ¨¡å‹è·¯å¾„")
        return None
    
    print("ğŸ“ å¯ç”¨çš„æ¨¡å‹:")
    for i, (name, path) in enumerate(available_models, 1):
        print(f"  {i}. {name}")
    
    try:
        choice = input(f"\nè¯·é€‰æ‹©æ¨¡å‹ (1-{len(available_models)}): ").strip()
        if choice.isdigit() and 1 <= int(choice) <= len(available_models):
            selected_model = available_models[int(choice) - 1][1]
            print(f"âœ… é€‰æ‹©æ¨¡å‹: {selected_model}")
            return selected_model
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
            return None
    except:
        return None

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ¤– æ¨¡å‹å¯¹è¯ç³»ç»Ÿ")
    print("=" * 60)
    
    # é€‰æ‹©æ¨¡å‹
    model_path = select_model()
    if not model_path:
        # å¦‚æœè‡ªåŠ¨é€‰æ‹©å¤±è´¥ï¼Œæ‰‹åŠ¨è¾“å…¥è·¯å¾„
        model_path = input("è¯·è¾“å…¥æ¨¡å‹è·¯å¾„: ").strip()
        if not os.path.exists(model_path):
            print("âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨")
            return
    
    # åˆå§‹åŒ–èŠå¤©æœºå™¨äºº
    try:
        chatbot = ChatBot(model_path)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¹‹å‰çš„å¯¹è¯è®°å½•
        conversations_dir = "./conversations"
        if os.path.exists(conversations_dir):
            conversation_files = [f for f in os.listdir(conversations_dir) if f.endswith('.json')]
            if conversation_files:
                print(f"\nğŸ“‚ å‘ç° {len(conversation_files)} ä¸ªå¯¹è¯è®°å½•")
                load_choice = input("æ˜¯å¦åŠ è½½æœ€è¿‘çš„å¯¹è¯è®°å½•? (y/N): ").strip().lower()
                if load_choice == 'y':
                    latest_file = max(conversation_files, key=lambda f: os.path.getctime(os.path.join(conversations_dir, f)))
                    chatbot.load_conversation(os.path.join(conversations_dir, latest_file))
        
        # å¼€å§‹èŠå¤©
        chatbot.start_chat()
        
        # é€€å‡ºå‰è¯¢é—®æ˜¯å¦ä¿å­˜
        if chatbot.conversation_history:
            save_choice = input("\næ˜¯å¦ä¿å­˜å¯¹è¯è®°å½•? (Y/n): ").strip().lower()
            if save_choice != 'n':
                chatbot.save_conversation()
        
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()